{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOo/IPfhJyoXI0V38jGmRmY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Step 1: Import Libraries\n","\n","import sys\n","import pandas as pd\n","import numpy as np\n","import sklearn\n","import matplotlib\n","import tensorflow as tf\n","print('Python: {}'.format(sys.version))\n","print('Pandas: {}'.format(pd.__version__))\n","print('Numpy: {}'.format(np.__version__))\n","print('Sklearn: {}'.format(sklearn.__version__))\n","print('Matplotlib: {}'.format(matplotlib.__version__))\n","print('TensorFlow: {}'.format(tf.__version__))\n","import matplotlib.pyplot as plt\n","from pandas.plotting import scatter_matrix\n","import seaborn as sns\n","\n","# Step 2: Load and Explore Dataset\n","# read the csv\n","\n","cleveland = pd.read_csv('heart.csv')\n","\n","# Make sure to use the correct path to your dataset\n","\n","print('Shape of DataFrame: {}'.format(cleveland.shape))\n","print(cleveland.loc[1])\n","cleveland.loc[280:]\n","\n","# remove missing data (indicated with a \"?\")\n","\n","data = cleveland[~cleveland.isin(['?'])]\n","data.loc[280:]\n","\n","# drop rows with NaN values from DataFrame\n","\n","data = data.dropna(axis=0)\n","data.loc[280:]\n","print(data.shape)\n","print(data.dtypes)\n","\n","# transform data to numeric to enable further analysis\n","\n","data = data.apply(pd.to_numeric)\n","print(data.dtypes)\n","print(data.describe())\n","\n","# plot histograms for each variable\n","\n","data.hist(figsize=(12, 12))\n","plt.show()\n","pd.crosstab(data.age, data.target).plot(kind=\"bar\", figsize=(20, 6))\n","plt.title('Heart Disease Frequency for Ages')\n","plt.xlabel('Age')\n","plt.ylabel('Frequency')\n","plt.show()\n","plt.figure(figsize=(10, 10))\n","sns.heatmap(data.corr(), annot=True, fmt='.1f')\n","plt.show()\n","age_unique = sorted(data.age.unique())\n","age_thalach_values = data.groupby('age')['thalach'].count().values\n","mean_thalach = [sum(data[data['age'] == age].thalach) /\n","age_thalach_values[i] for i, age in enumerate(age_unique)]\n","plt.figure(figsize=(10, 5))\n","sns.pointplot(x=age_unique, y=mean_thalach, color='red', alpha=0.8)\n","plt.xlabel('Age', fontsize=15, color='blue')\n","plt.xticks(rotation=45)\n","plt.ylabel('Thalach', fontsize=15, color='blue')\n","plt.title('Age vs Thalach', fontsize=15, color='blue')\n","plt.grid()\n","plt.show()\n","# Step 3: Create Training and Testing Datasets\n","\n","X = np.array(data.drop(['target'], axis=1))\n","y = np.array(data['target'])\n","mean = X.mean(axis=0)\n","X -= mean\n","std = X.std(axis=0)\n","X /= std\n","from sklearn import model_selection\n","X_train,X_test,y_train, y_test = model_selection.train_test_split(X,\n","y, stratify=y, random_state=42, test_size=0.2)\n","from tensorflow.keras.utils import to_categorical\n","Y_train = to_categorical(y_train, num_classes=None)\n","Y_test = to_categorical(y_test, num_classes=None)\n","print(Y_train.shape)\n","print(Y_train[:10])\n","\n","#Step 4: Building and Training the Neural Network\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","def create_model():\n","  model = Sequential()\n","  model.add(Dense(16, input_dim=13, kernel_initializer='normal',\n","                  kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n","  model.add(Dropout(0.25))\n","  model.add(Dense(8, kernel_initializer='normal',\n","                  kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n","  model.add(Dropout(0.25))\n","  model.add(Dense(2, activation='softmax'))\n","  adam = Adam(learning_rate=0.001) # Corrected parameter name\n","  model.compile(loss='categorical_crossentropy',\n","                optimizer='rmsprop', metrics=['accuracy'])\n","  return model\n","model = create_model()\n","print(model.summary())\n","history= model.fit(X_train,Y_train,validation_data=(X_test, Y_test),epochs=50, batch_size=10)\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model Accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'])\n","plt.show()\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train','test'])\n","plt.show()\n","# Step 5: Improving Results - A Binary Classification Problem\n","\n","Y_train_binary = y_train.copy()\n","Y_test_binary = y_test.copy()\n","\n","Y_train_binary[Y_train_binary > 0] = 1\n","Y_test_binary[Y_test_binary > 0] = 1\n","def create_binary_model():\n","  model = Sequential()\n","  model.add(Dense(16,input_dim=13,kernel_initializer='normal',\n","                  kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n","  model.add(Dropout(0.25))\n","  model.add(Dense(8,kernel_initializer='normal',\n","                  kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n","  model.add(Dropout(0.25))\n","  model.add(Dense(1, activation='sigmoid'))\n","  adam = Adam(learning_rate=0.001)\n","  model.compile(loss='binary_crossentropy', optimizer='rmsprop',metrics=['accuracy'])\n","  return model\n","binary_model = create_binary_model()\n","print(binary_model.summary())\n","history=binary_model.fit(X_train,Y_train_binary,validation_data=(X_test, Y_test_binary), epochs=50, batch_size=10)\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model Accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'])\n","plt.show()\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'])\n","plt.show()\n","# Step 6: Results and Metrics\n","\n","from sklearn.metrics import classification_report, accuracy_score,confusion_matrix, precision_score, recall_score, f1_score\n","\n","# Categorical model predictions and metrics\n","\n","categorical_pred = np.argmax(model.predict(X_test), axis=1)\n","\n","print('Results for Categorical Model')\n","print(accuracy_score(y_test, categorical_pred))\n","print(classification_report(y_test, categorical_pred))\n","\n","# Binary model predictions and metrics\n","\n","binary_pred = np.round(binary_model.predict(X_test)).astype(int)\n","print('Results for Binary Model')\n","print(accuracy_score(Y_test_binary, binary_pred))\n","print(classification_report(Y_test_binary, binary_pred))\n","\n","# Confusion Matrix\n","\n","cm = confusion_matrix(Y_test_binary, binary_pred)\n","plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Disease\", \"Disease\"], yticklabels=[\"No Disease\", \"Disease\"])\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","# Precision, Recall, F1-Score\n","\n","precision = precision_score(Y_test_binary, binary_pred)\n","recall = recall_score(Y_test_binary, binary_pred)\n","f1 = f1_score(Y_test_binary, binary_pred)\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1-Score: {f1:.2f}\")\n","print(\"\\nClassificationReport:\\n\",classification_report(Y_test_binary, binary_pred, target_names=[\"NoDisease\", \"Disease\"]))"],"metadata":{"id":"5I5sySgxYKCt"},"execution_count":null,"outputs":[]}]}